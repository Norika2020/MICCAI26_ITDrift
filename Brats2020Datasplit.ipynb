{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1_fWdLIERVDpIxxNDvULqBxSQvOQEQumv","authorship_tag":"ABX9TyP4ANS4joiXMHbmfrT/u2Cv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrUSAv4N7Sn3","executionInfo":{"status":"ok","timestamp":1764324491028,"user_tz":0,"elapsed":10706,"user":{"displayName":"Norika Duan","userId":"14097027443394439212"}},"outputId":"80fdbfe8-4947-48ea-cde6-31fdc126f9b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}],"source":["!pip install scikit-learn pandas\n","\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import pickle"]},{"cell_type":"code","source":["# Adjust paths if needed\n","name_map = pd.read_csv(\"name_mapping.csv\")\n","surv = pd.read_csv(\"survival_info.csv\")\n","\n","print(\"name_mapping columns:\", name_map.columns.tolist())\n","print(\"survival_info columns:\", surv.columns.tolist())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brhQkZkL7xR3","executionInfo":{"status":"ok","timestamp":1764324650267,"user_tz":0,"elapsed":43,"user":{"displayName":"Norika Duan","userId":"14097027443394439212"}},"outputId":"83c93627-caa3-4454-f65f-ddb621cf9fa3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["name_mapping columns: ['Grade', 'BraTS_2017_subject_ID', 'BraTS_2018_subject_ID', 'TCGA_TCIA_subject_ID', 'BraTS_2019_subject_ID', 'BraTS_2020_subject_ID']\n","survival_info columns: ['Brats20ID', 'Age', 'Survival_days', 'Extent_of_Resection']\n"]}]},{"cell_type":"code","source":["# Make sure we have a consistent ID column\n","# name_mapping usually has something like 'BraTS_2020_subject_ID'\n","name_map = name_map.rename(columns={\"BraTS_2020_subject_ID\": \"Brats20ID\"})\n","\n","# survival_info.csv usually already has 'Brats20ID'\n","# Merge on Brats20ID to get Grade + Age + Survival, etc.\n","meta = pd.merge(name_map, surv, on=\"Brats20ID\", how=\"left\")\n","\n","print(\"Merged shape:\", meta.shape)\n","print(meta.head())\n","print(\"\\nGrade value counts:\")\n","print(meta[\"Grade\"].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZR6lHye8awt","executionInfo":{"status":"ok","timestamp":1764325677544,"user_tz":0,"elapsed":17,"user":{"displayName":"Norika Duan","userId":"14097027443394439212"}},"outputId":"67bea13a-a4c1-484a-d919-511a67e8dbd5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Merged shape: (369, 9)\n","  Grade BraTS_2017_subject_ID BraTS_2018_subject_ID TCGA_TCIA_subject_ID  \\\n","0   HGG   Brats17_CBICA_AAB_1   Brats18_CBICA_AAB_1                  NaN   \n","1   HGG   Brats17_CBICA_AAG_1   Brats18_CBICA_AAG_1                  NaN   \n","2   HGG   Brats17_CBICA_AAL_1   Brats18_CBICA_AAL_1                  NaN   \n","3   HGG   Brats17_CBICA_AAP_1   Brats18_CBICA_AAP_1                  NaN   \n","4   HGG   Brats17_CBICA_ABB_1   Brats18_CBICA_ABB_1                  NaN   \n","\n","  BraTS_2019_subject_ID             Brats20ID     Age Survival_days  \\\n","0   BraTS19_CBICA_AAB_1  BraTS20_Training_001  60.463           289   \n","1   BraTS19_CBICA_AAG_1  BraTS20_Training_002  52.263           616   \n","2   BraTS19_CBICA_AAL_1  BraTS20_Training_003  54.301           464   \n","3   BraTS19_CBICA_AAP_1  BraTS20_Training_004  39.068           788   \n","4   BraTS19_CBICA_ABB_1  BraTS20_Training_005  68.493           465   \n","\n","  Extent_of_Resection  \n","0                 GTR  \n","1                 GTR  \n","2                 GTR  \n","3                 GTR  \n","4                 GTR  \n","\n","Grade value counts:\n","Grade\n","HGG    293\n","LGG     76\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["We’ll do this in two stages:\n","\n","First: 85% train+val, 15% test\n","\n","Second: within the 85%, split into 70% train, 15% val\n","So overall ≈ 70/15/15."],"metadata":{"id":"-q6YiUsWBFAH"}},{"cell_type":"code","source":["# First: train_val (85%) vs test (15%), stratified by Grade\n","train_val_df, test_df = train_test_split(\n","    meta,\n","    test_size=0.15,\n","    random_state=42,\n","    stratify=meta[\"Grade\"]\n",")\n","\n","# Second: within train_val, split into train (70%) and val (15%)\n","# Proportion for val relative to train_val = 0.15 / 0.85 ≈ 0.1765\n","val_ratio_within_trainval = 0.15 / 0.85\n","\n","train_df, val_df = train_test_split(\n","    train_val_df,\n","    test_size=val_ratio_within_trainval,\n","    random_state=42,\n","    stratify=train_val_df[\"Grade\"]\n",")\n","\n","print(\"Total:\", len(meta))\n","print(\"Train:\", len(train_df))\n","print(\"Val:  \", len(val_df))\n","print(\"Test: \", len(test_df))\n","\n","print(\"\\nGrade counts (Train):\")\n","print(train_df[\"Grade\"].value_counts())\n","print(\"\\nGrade counts (Val):\")\n","print(val_df[\"Grade\"].value_counts())\n","print(\"\\nGrade counts (Test):\")\n","print(test_df[\"Grade\"].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IYTaxRN8q0z","executionInfo":{"status":"ok","timestamp":1764325833518,"user_tz":0,"elapsed":12,"user":{"displayName":"Norika Duan","userId":"14097027443394439212"}},"outputId":"ef16f48c-cf34-4764-9927-c08f18617a1d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Total: 369\n","Train: 257\n","Val:   56\n","Test:  56\n","\n","Grade counts (Train):\n","Grade\n","HGG    204\n","LGG     53\n","Name: count, dtype: int64\n","\n","Grade counts (Val):\n","Grade\n","HGG    45\n","LGG    11\n","Name: count, dtype: int64\n","\n","Grade counts (Test):\n","Grade\n","HGG    44\n","LGG    12\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["These plain text files are handy for our own scripts:"],"metadata":{"id":"fbxQEsm1BLJv"}},{"cell_type":"code","source":["train_ids = train_df[\"Brats20ID\"].tolist()\n","val_ids   = val_df[\"Brats20ID\"].tolist()\n","test_ids  = test_df[\"Brats20ID\"].tolist()\n","\n","# Save as simple text files (one ID per line)\n","with open(\"train_ids.txt\", \"w\") as f:\n","    f.write(\"\\n\".join(train_ids))\n","\n","with open(\"val_ids.txt\", \"w\") as f:\n","    f.write(\"\\n\".join(val_ids))\n","\n","with open(\"test_ids.txt\", \"w\") as f:\n","    f.write(\"\\n\".join(test_ids))\n","\n","print(\"Saved train_ids.txt, val_ids.txt, test_ids.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1GQIOus7A7pk","executionInfo":{"status":"ok","timestamp":1764325929856,"user_tz":0,"elapsed":43,"user":{"displayName":"Norika Duan","userId":"14097027443394439212"}},"outputId":"1736d5d1-76aa-4399-c84b-c1882058d140"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved train_ids.txt, val_ids.txt, test_ids.txt\n"]}]},{"cell_type":"code","source":["# Build the split structure for nnU-Net\n","# We'll define a single fold (fold 0) with our train/val split\n","split_dict = {\n","    \"train\": train_ids,\n","    \"val\":   val_ids\n","}\n","\n","splits = [split_dict]  # nnU-Net expects a list of folds\n","\n","# Path to nnU-Net dataset folder\n","# Adjust this to match your actual nnUNet_raw structure\n","# Example: nnUNet_raw/Dataset999_BraTS2020/\n","dataset_id = \"Dataset001_BraTS2020\"  # <- change to your DatasetXXX name\n","nnunet_raw_path = \"/content/drive/MyDrive/MEDICAL/InfoTheo_dataset/nnUNet_raw\"  # or your path if different\n","\n","dataset_folder = os.path.join(nnunet_raw_path, dataset_id)\n","os.makedirs(dataset_folder, exist_ok=True)\n","\n","splits_file = os.path.join(dataset_folder, \"splits_final.pkl\")\n","\n","with open(splits_file, \"wb\") as f:\n","    pickle.dump(splits, f)\n","\n","print(\"Saved splits_final.pkl to:\", splits_file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ou2vXa2BTKW","executionInfo":{"status":"ok","timestamp":1764326334658,"user_tz":0,"elapsed":51,"user":{"displayName":"Norika Duan","userId":"14097027443394439212"}},"outputId":"39577c97-2509-49dc-9e35-552f1e5b506d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved splits_final.pkl to: /content/drive/MyDrive/MEDICAL/InfoTheo_dataset/nnUNet_raw/Dataset001_BraTS2020/splits_final.pkl\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jD_q8Sb-C1_Q"},"execution_count":null,"outputs":[]}]}